\chapter{Estudo de caso - Parte I} \label{cha:estudoi}

\section{PA analisado} \label{sec:estudoi-pa}
Neste estudo de caso foram utilizados os dados extraídos de um modelo Advanced Memory Polynomial (AMP) com um sinal LTE com l153,6 MHz. O AMP foi treinado para representar o esquemático de um PA multímodo proposto para a tecnologia CMOS 130 nm, operando no sexto modo e possuindo uma frequência central de 2,4 GHz argura de banda de 20 MHz, com a frequência de amostragem de \cite{dos2017fully} \cite{schuartz2019reduced}. Para os dados de treinamento foram utilizadas 3000 amostras, enquanto 2000 amostras foram utilizadas nas etapas de validação.

\section{Ferramentas} \label{sec:estudoi-ferr}
Diversas ferramentas existem para o desenvolvimento de modelos computacionais, neste estudo de caso foi escolhida como ferramenta principal a linguagem de programação Python. Python linguagem de programação multiparadigma e com alto nível de abstração, que permite a utilização de bibliotecas construídas em linguagens de programação mais eficientes na utilização dos recursos computacionais como C/C++, Fortran e Rust \cite{Ramalho2022-zg}.

Para a construção dos TLPs foi utilizada a biblioteca TensorFlow, com a utilização da biblioteca Keras para a construção dos modelos através de sua API funcional. Desenvolvida pelo Google utilizando-se C++, o TensorFlow é uma biblioteca para a criação e o treinamento de projetos de aprendizagem de máquina, com foco em redes neurais artificiais \cite{tensorflow2015-whitepaper}.

Para a representação dos valores, foi utilizada a biblioteca Numpy, construída utilizando-se C, que é uma biblioteca voltada para a computação cientifica através do uso de matrizes de valores numéricos \cite{harris2020array}.

Para a resolução dos problemas de otimização para encontrar os valores do problema inverso, a biblioteca utilizada foi a Scipy, construída utilizando-se principalmente Python, Fortran e C \cite{2020SciPy-NMeth}.

A biblioteca Polars, construída em Rust, foi utilizada para a representação dos dados em formado tabular. Para a visualização dos destes dados, as bibliotecas Matplotlib e Seaborn foram utilizadas \cite{Hunter:2007} \cite{Waskom2021}.

\section{Metodologia} \label{sec:estudoi-meto}
O primeiro passo para obtenção dos resultados é a construção do modelo do PA utilizando-se dois TLPs na topologia apresentada, o modelo foi construído em Python e os TLPs foram construídos utilizando-se as bibliotecas TensorFlow e Keras. Como parâmetros para a construção do modelo foram especificados a profundidade de memória M, a quantidade de perceptrons presentes na camada oculta HL e a função de ativação.

Para o treinamento do modelo foi escolhido como método de otimização o Levenberg-Marquardt e como função de perda o erro quadrático médio (MSE). O treinamento foi efetuado através da função padrão presente na biblioteca TensorFlow. Como métrica para comparar os resultados do treinamento e da validação do modelo foi escolhido o NMSE.

Uma função representando o problema inverso foi criada de forma tal a quando o seu resultado for zero, o processo de resolução do problema inverso seja exitoso. Essa função é responsável por receber o valor esperado para a saída do modelo e o valor proposto pelo método de resolução como entrada atual do modelo. A partir do valor proposto, ao ser passado ao modelo junto com as entradas passadas conhecidas, é encontrada a saída do modelo. A função retorna a diferença entre a saída obtida do modelo e a saída esperado multiplicada por um fator gama. Esse fator gama é igual a 1 caso a entrada proposta possua amplitude menor que 3 e é igual a amplitude da entrada proposta caso contrário.

Dois conjuntos de 9 entradas propostas foram criados, sendo a diferença entre eles a amplitude, o primeiro conjunto possuindo uma amplitude 0,5 como amplitude e o segundo 2,5. Enquanto as 9 fases escolhida foram distribuídas de forma uniforme ao redor do círculo unitário, iniciando-se em 0. Valores na \autoref{tab:valores}.

\tabela{Entradas iniciais utilizadas}
{
\begin{tabular}{l|l|l}
\hline
    & \multicolumn{2}{c}{\textbf{Amplitude}} \\ \hline
    \textbf{Fase (rad)} & \textit{0.5} & \textit{2.5} \\ \hline
    \textit{0}& 0.5$\angle$0 & 2.5$\angle$0 \\ \hline
    \textit{2$\pi$/9} & 0.5$\angle$2$\pi$/9  & 2.5$\angle$2$\pi$/9  \\ \hline
    \textit{4$\pi$/9} & 0.5$\angle$4$\pi$/9  & 2.5$\angle$4$\pi$/9  \\ \hline
    \textit{6$\pi$/9} & 0.5$\angle$6$\pi$/9  & 2.5$\angle$6$\pi$/9  \\ \hline
    \textit{8$\pi$/9} & 0.5$\angle$8$\pi$/9  & 2.5$\angle$8$\pi$/9  \\ \hline
    \textit{10$\pi$/9}& 0.5$\angle$10$\pi$/9 & 2.5$\angle$10$\pi$/9 \\ \hline
    \textit{12$\pi$/9}& 0.5$\angle$12$\pi$/9 & 2.5$\angle$12$\pi$/9 \\ \hline
    \textit{14$\pi$/9}& 0.5$\angle$14$\pi$/9 & 2.5$\angle$14$\pi$/9 \\ \hline
    \textit{16$\pi$/9}& 0.5$\angle$16$\pi$/9 & 2.5$\angle$16$\pi$/9 \\ \hline
\end{tabular}
\label{tab:valores}
}
{O autor}{tab:valores}{}{Valores utilizados na resolução do problema inverso}

A função \textit{optimize.root}, da biblioteca SciPy, foi utilizada para encontrar as raízes da função que representa o problema inverso. O método de otimização utilizado foi o HYBRD \cite{powell1970hybrid}.

Com os resultados de todas as entradas propostas obtidas para todas as amostras analisadas, duas informações são extraídas: O NMSE entre a saída esperada e a saída obtida e o NMSE entre a entrada esperada e a entrada obtida pela resolução do problema inverso. E é a partir destes resultados que as análises presentes neste relatório serão feitas, outras informações adicionais também serão utilizadas de forma complementar.

\section{Modelagem e validação do modelo do PA} \label{sec:estudoi-model}
Para o modelo de PA utilizado nesse estudo de caso foi definida uma profundidade de memória M=3 e um número de perceptrons na camada oculta HL=7, totalizando-se 85 parâmetros para a parte real e mais 85 parâmetros para a parte imaginária do modelo.

A função de ativação foi a tangente hiperbólica, o total de entradas foi igual a 10, na camada de saída foi utilizada uma função de ativação linear, para a busca dos coeficientes foi utilizada a métrica MSE e o processo de busca usou o algoritmo Levenberg-Marquardt. Sendo a parte real e a parte imaginária treinadas separadamente.

O modelo foi capaz de ter um NMSE de -60.9 para os dados de treinamento e de -42.9 para os dados de validação. A \autoref{fig:extracao_pa} apresenta os valores da amplitude da saída em relação a entrada para os dados medidos e para os gerados pelo modelo para o conjunto de treinamento, enquanto a \autoref{fig:validacao_pa} mostra as mesmas informações para o conjunto de validação.

\imagem{Dados de extração do PA}{
\label{fig:extracao_pa}
\includegraphics[width = 0.8\textwidth]{fig/extracao_pa.png}
}{O autor}{fig:extracao_pa}{}{Dados de extração do PA.}

\imagem{Dados de validação do PA}{
\label{fig:validacao_pa}
\includegraphics[width = 0.8\textwidth]{fig/validacao_pa.png}
}{O autor}{fig:validacao_pa}{}{Dados de validação do PA.}

\section{Uso do PI na análise do comportamento} \label{sec:estudoi-pi}

\subsection{Efeitos da continuidade da NN} \label{subsec:estudoi-pi-conti}
As redes neurais possuem a capacidade de generalizar o comportamento da função e estender esse comportamento para regiões não mapeadas, causando uma complicação adicional. Pois mesmo para entradas de menor amplitude, uma região descrente e não mapeada pode ser formada, como visto na \autoref{fig:continuidade_pa}. Um contorno a isso é penalizar a otimização na região não mapeada, multiplicando o erro encontrado por um coeficiente proporcional a amplitude de entrada proposto. Causar uma descontinuidade nessa região em testes preliminares se mostrou ineficiente e não foi adotado esse método.

\imagem{Dados da continuidade do PA}{
\label{fig:continuidade_pa}
\includegraphics[width = 0.8\textwidth]{fig/validacao_pa.png}
}{O autor}{fig:continuidade_pa}{}{Dados da continuidade do PA.}

\subsection{Efeito dos valores iniciais na solução do PI e distribuição por amplitudes} \label{subsec:estudoi-pi-efeito}
Os 18 diferentes valores de entrada inicial para a solução do problema inverso presentes na \autoref{tab:valores} foram feitos e os resultados foram separados em dois conjuntos, o conjunto com amplitude de 0,5 e o com amplitude de 2,5.

Nas figura () e figura () pode-se observar o comportamento destes dois principais conjuntos, no qual vemos a formação de três regiões. A região superior representa os valores que não convergiram, enquanto a inferior é dividida entre os que convergiram para o valor esperado e as que encontraram um valor de entrada não esperado. No gráfico está representado o erro entre o valor de saída e de entrada do modelo por meio do NMSE.

FIGURAS GIGANTES

A distribuição por amplitudes e fases pode ser vista na tabela () para a amplitude de 0,5 e na tabela () para a amplitude de 2,5.


\subsection{Efeito das entradas para o problema inverso} \label{subsec:estudoi-pi-entradas}
Para se analisar o comportamento do modelo direto do amplificador 

\section{Treinamento da inversa} \label{sec:estudoi-inv}
Os resultados práticos no treinamento da inversa do PA através da mesma topologia, utilizando um valor de profundidade de memória M = 3 e uma quantidade de perceptrons na camada oculta HL = 7, deixam clara a maior dificuldade que o modelo inverso possui para generalizar os resultados na região não-linear e que mesmo o resultado do treinamento apresenta um desemprenho inferior ao do modelo direto. Isso pode ser observado graficamente na figuras () e na figura (), respectivamente os dados de treinamento, com um NMSE de -49,326, e de validação, com um NMSE de -20,025.

figura
figura

\chapter{Conclusão} \label{cha:conclusao}
O problema inverso se mostra através dos resultados presentes uma ferramenta promissora para a análise do comportamento de modelos computacionais de PAs e de suas inversas. Existe uma grande região para se aprofundar nestas análises, sendo esse estudo de caso somente uma pequena amostra das possibilidades, que já é capaz de auxiliar a delimitar as regiões mais estáveis em um modelo a partir da aplicação de diferentes amplitudes como parâmetro inicial no processo de resolução do problema inverso.